Ext.data.JsonP.Microsoft_CognitiveServices_SpeechRecognition_DataRecognitionClient({"tagname":"class","name":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","autodetected":{},"files":[{"filename":"speech.1.0.0.js","href":"speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient"}],"members":[{"name":"endAudio","tagname":"method","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"method-endAudio","meta":{}},{"name":"sendAudio","tagname":"method","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"method-sendAudio","meta":{}},{"name":"onError","tagname":"event","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"event-onError","meta":{}},{"name":"onFinalResponseReceived","tagname":"event","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"event-onFinalResponseReceived","meta":{}},{"name":"onIntentReceived","tagname":"event","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"event-onIntentReceived","meta":{}},{"name":"onPartialResponseReceived","tagname":"event","owner":"Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","id":"event-onPartialResponseReceived","meta":{}}],"alternateClassNames":[],"aliases":{},"id":"class-Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient","short_doc":"Use the DataRecognitionClient to do speech recognition with data (for example from a file or audio source). ...","component":false,"superclasses":[],"subclasses":[],"mixedInto":[],"mixins":[],"parentMixins":[],"requires":[],"uses":[],"html":"<div><pre class=\"hierarchy\"><h4>Files</h4><div class='dependency'><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient' target='_blank'>speech.1.0.0.js</a></div></pre><div class='doc-contents'><p>Use the DataRecognitionClient to do speech recognition with data (for example from a file or audio source).\nThe data is broken up into buffers and each buffer is sent to the Speech Recognition Service.\nNo modification is done to the buffers, so the user can apply their Silence Detection. Returns only text\nrecognition results.</p>\n</div><div class='members'><div class='members-section'><div class='definedBy'>Defined By</div><h3 class='members-title icon-method'>Methods</h3><div class='subsection'><div id='method-endAudio' class='member first-child not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-method-endAudio' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-method-endAudio' class='name expandable'>endAudio</a>( <span class='pre'></span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Notify the server that client is done sending audio buffers to the Speech Recognition Service. ...</div><div class='long'><p>Notify the server that client is done sending audio buffers to the Speech Recognition Service.\nThis work is queued onto a background worker.</p>\n</div></div></div><div id='method-sendAudio' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-method-sendAudio' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-method-sendAudio' class='name expandable'>sendAudio</a>( <span class='pre'>buffer, actualAudioBytesInBuffer</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Send buffers of audio to the Speech Recognition Service. ...</div><div class='long'><p>Send buffers of audio to the Speech Recognition Service.\nThis work is queued onto a background worker.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>buffer</span> : Object<div class='sub-desc'><p>(ArrayBuffer) The data bytes of audio to send to the Server</p>\n</div></li><li><span class='pre'>actualAudioBytesInBuffer</span> : number<div class='sub-desc'><p>The buffer size is allowed to be larger than the actual audio data in the buffer, so\nthis parameter states the size of the actual data in the buffer.</p>\n</div></li></ul></div></div></div></div></div><div class='members-section'><div class='definedBy'>Defined By</div><h3 class='members-title icon-event'>Events</h3><div class='subsection'><div id='event-onError' class='member first-child not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-event-onError' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-event-onError' class='name expandable'>onError</a>( <span class='pre'>errorCode, response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when an error is detected. ...</div><div class='long'><p>Invoked when an error is detected.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>errorCode</span> : Object<div class='sub-desc'><p>{number} The error code.</p>\n</div></li><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>The body of the http response for the error.</p>\n</div></li></ul></div></div></div><div id='event-onFinalResponseReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-event-onFinalResponseReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-event-onFinalResponseReceived' class='name expandable'>onFinalResponseReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>In ShortPhrase mode, the client gets one final multiple n-best choice result\nwhen recognition is complete. ...</div><div class='long'><p>In ShortPhrase mode, the client gets one final multiple n-best choice result\nwhen recognition is complete.  This event will be fired for that one final\nmultiple n-best choice result.</p>\n\n<p>In LongDictation mode, the client will receive multiple final results,\nbased on where the server thinks sentence pauses are. This event will be fired\nfor each final result, as the server determines them.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>A streamlined RecognitionResult which contains the n-best recognized\n                text results and their confidences.  A StreamlinedRecognitionResults can\n                then further be used to obtain a SpeechRecognitionResults which has even\n                more n-best result data.</p>\n</div></li></ul></div></div></div><div id='event-onIntentReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-event-onIntentReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-event-onIntentReceived' class='name expandable'>onIntentReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when an intent event is received. ...</div><div class='long'><p>Invoked when an intent event is received.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : Object<div class='sub-desc'><p>{string} The structured intent response.</p>\n</div></li></ul></div></div></div><div id='event-onPartialResponseReceived' class='member  not-inherited'><a href='#' class='side expandable'><span>&nbsp;</span></a><div class='title'><div class='meta'><span class='defined-in' rel='Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient'>Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient</span><br/><a href='source/speech.1.0.0.html#Microsoft-CognitiveServices-SpeechRecognition-DataRecognitionClient-event-onPartialResponseReceived' target='_blank' class='view-source'>view source</a></div><a href='#!/api/Microsoft.CognitiveServices.SpeechRecognition.DataRecognitionClient-event-onPartialResponseReceived' class='name expandable'>onPartialResponseReceived</a>( <span class='pre'>response</span> )<span class=\"signature\"></span></div><div class='description'><div class='short'>Invoked when during the recognition process, the Speech Recognition\nserver can create a hypothesis on what the recogn...</div><div class='long'><p>Invoked when during the recognition process, the Speech Recognition\nserver can create a hypothesis on what the recognized text might be.  As more audio\nstreams in, the hypothesis might change, and get longer as well.  So with each\nhypothesis, the server will call back and this event will be fired and contain\nthe current hypothesis text.</p>\n<h3 class=\"pa\">Parameters</h3><ul><li><span class='pre'>response</span> : string<div class='sub-desc'><p>The display text</p>\n</div></li></ul></div></div></div></div></div></div></div>","meta":{}});